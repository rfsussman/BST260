[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BST 260 Introduction to Data Science",
    "section": "",
    "text": "Preface"
  },
  {
    "objectID": "index.html#downloading-course-materials-using-git",
    "href": "index.html#downloading-course-materials-using-git",
    "title": "BST 260 Introduction to Data Science",
    "section": "Downloading course materials using Git",
    "text": "Downloading course materials using Git\nYou can download the quarto files used to create the course notes using Git. You can update files using git pull but you will not be able to change the course notes on the main repository. This means that if you edit the files and then try to update then using git pull you will encounter conflicts. For this reason recommend that you make a copy before editing files. We have edited the .gitignore file so that if you add the word notes to your filenames, git will not track the files. So we recommend that you before editing you make a copy of the file and notes to the filename. For example 01-unix.qmd to 01-unix-notes.qmd.\nYou can download the files using git clone like this:\n\nOpen a terminal and navigate to the directory you want to keep these notes in.\nType git clone  https://github.com/datasciencelabs/2023.git\n\nor using RStudio like this:\n\nGot to https://github.com/datasciencelabs/2023\nClick on the green “Clone or Download” on Github and copy the link.\nOpen RStudio, and go to File &gt; New Project &gt; Version Control &gt; Git, and paste in the link you just copied. Under “Create Project as Sub-directory of”, browse and select a folder where you want the course materials to go.\nPress “Create Project”. This will create a folder called 2023 in the folder you selected in step 3.\nNow, you can open this project using the projects tab in the upper right of RStudio, or going to File &gt; Open Project and then navigating to the 2023 folder and opening the .Rproj file.\n\nOnce you cloned the course repository and want to get updates, you must use git pull to get updates. You can do this in the terminal or on the RStudio’s Git pane.\n\nAssociating an existing directory\nIf you already cloned the repository outside of RStudio, you can associate the directory that was created in that step with RStudio. In RStudio, go to File &gt; New Project &gt; Existing Directory, and then navigate / click on the 2023 folder. Then click “Create Project”. Then you can follow step 5 above to open the project when you launch RStudio.\n\n\nForking the repository\nAn alternative more advanced way to cloning the directory is creating a fork. Forking a repository on GitHub allows you to create a copy of a project under your own GitHub account. This lets you make changes without affecting the original repository. Here’s how you can fork a repository on GitHub:\n\nLog In to GitHub:\n\nMake sure you are logged in to your GitHub account.\n\nNavigate to the Repository:\n\nGo to the main page of the repository you want to fork: https://github.com/datasciencelabs/2023\n\nClick the ‘Fork’ Button:\n\nIn the top-right corner of the repository’s page, you’ll find the “Fork” button. Click on it.\n\nChoose an Account:\n\nIf you are a member of any organizations, GitHub will ask you where you’d like to fork the repository. Choose your personal account unless you want to fork it to an organization.\n\nWait for the Forking Process to Complete:\n\nGitHub will then create a copy of the repository in your account. You’ll see an animation indicating the process, and once it’s done, you’ll be redirected to the forked repository under your account.\n\nClone Your Forked Repository:\n\nTo work with the forked repository on your local machine, you can clone it. Navigate to the main page of your forked repo, click on the green “Code” button, copy the URL, and then use the following command in your terminal or command prompt:\ngit clone [URL_you_copied]\n\n\nYou can continue to update the forked repository by doing the following:\n\nNavigate to Your Local Repository:\n\nOpen a terminal or command prompt.\nNavigate to the directory where you have your forked repository.\n\nAdd the Original Repository as an Upstream Remote:\n\nUse the following command to add the original repository as an upstream remote:\ngit remote add upstream [URL_of_original_repository]\nFor example, if the original repository’s URL is https://github.com/original-owner/original-repo.git, the command would be:\ngit remote add upstream https://github.com/original-owner/original-repo.git\n\nFetch Changes from the Upstream:\n\nUse the following command to fetch changes from the upstream:\ngit fetch upstream\n\nMerge Changes into Your Local Branch:\n\nFirst, ensure you are on the branch into which you want to merge the upstream changes, typically the main or master branch:\ngit checkout main\nThen, merge the changes from the upstream’s main or master branch:\ngit merge upstream/main\n\nPush Changes to Your Forked Repository on GitHub (if needed):\n\nIf you want these changes to reflect in your GitHub fork, push them:\ngit push origin main\n\n\nNow your fork is synchronized with the original repository. Whenever you want to pull in new changes from the original repository in the future, you just need to repeat steps 3-5.\nTo avoid conflicts you sill want to avoid editing the course notes files and instead make copies."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Course description",
    "section": "",
    "text": "This course introduces UNIX/Linux shell, version control with git and GitHub, R programming, data wrangling with dplyr and data.table, data visualization with ggplot2 and shiny, and reproducible document preparation with RStudio, knitr and markdown. We briefly introduce Monte Carlo simulations, statistical modeling, high-dimensional data techniques, and machine learning and how these are applied to real data. Throughout the course, we use motivating case studies and data analysis problem sets based on challenges similar to those you encounter in scientific research.\nLectures will be mostly live coding. We will go over exercises and challenges together but will pause 1-4 times per lectures so students can complete exercises on their own. The midterm questions will be selected from the exercises presented in class. Some time will be dedicated to answering problem set questions. Lectures will not be recorded.\nStudents are required to have a GitHub account and create a repository for the course.\nProblem sets are mostly composed of open ended questions. Submission should be in the form of a scientific report. Problem set submission need to be completely reproducible. Specifically, students are expected to upload a Quarto document to their GitHub class repository that graders can compile into a readable report."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "The schedule is subject to change.\n\n\n\n\n\n\nDate\n\n\nModule\n\n\nTopics\n\n\n\n\nMon, Aug 28\n\n\nProductivity Tools\n\n\n\n RStudio, RStudio Projects, Quarto, Unix\n\n\n\n\n\nWed, Aug 30\n\n\nProductivity Tools\n\n\n\nGit and GitHub      \n\n\n\n\n\nMon, Sep 4\n\n\n\nNo class\n\n\n\nLabor day\n\n\n\n\nWed, Sep 6\n\n\n\nR\n\n\n\n\n\nR Basics: The workspace, data types, coercing, lists, packages, namespaces, help, creating vectors, object oriented programming.\n\n\nVectorization: Vector arithmetics, sapply, split, cut, lapply, subsetting, sorting\n\n\n\n\n\n\nMon, Sep 11\n\n\nR \n\n\n\n\nIntroduction to Tidyverse: tidy data, mutate, select, filter, the pipe, summarize, group_by, sorting, and the purrr package\n\n\nDates and time: Date class and the lubridate package\n\n\n\n\n\n\nWed, Sep 13\n\n\nR\n\n\n\n\nImporting data\n\n\nFile types: binary, ascii, unicode\n\n\nLocalesImporting data\n\n\nDownloading files\n\n\n\n\nThe data.table package\n\n\n\n\n\n\nMon, Sep 18\n\n\nData visualization\n\n\n\n\nVisualizing Distributions: Summary statistics, distributions, histograms, smooth densities, the normal distribution, quantiles, percentiles, and boxplots.\n\n\nGrammar of graphics and the basics of the ggplot2 package\n\n\n\n\n\n\nWed, Sep 20\n\n\nData visualization\n\n\n\n\nData visualization principles\n\n\nggplot2 geometries\n\n\n\n\n\n\nFri, Sep 22\n\n\nProblem set 1 due\n\n\n\n\n\n\nMon, Sep 25\n\n\nData wrangling \n\n\n\n\nReshaping data\n\n\nJoining tables\n\n\n\n\n\n\nWed, Sep 27\n\n\nData wrangling \n\n\n\n\nWeb scraping\n\n\nString processing\n\n\nText mining\n\n\n\n\n\n\n\nMon, Oct 2\n\n\n\nProbability\n\n\n\n\nMonte Carlo simulations\n\n\nRandom Variables\n\n\nCentral Limit Theorem\n\n\nProbability case studies: Roulette, Poker, Birthday problem, Monte Hall, insurance\n\n\n\n\n\n\n\nWed, Oct 4\n\n\n\nInference\n\n\n\n\nPolls\n\n\nGuess the proportion of blue beads competition\n\n\nConfidence intervals\n\n\nData-driven models\n\n\n\n\n\n\n\nFri, Oct 6\n\n\n\nFinal project title due\n\n\n\n Submit title and a describe your plans to obtain data\n\n\n\n\n\n\nMon, Oct 9\n\n\n\nNo class\n\n\nIndigenous Peoples’ Day\n\n\n\n\n\nWed, Oct 11\n\n\n\nInference\n\n\n\n\nBayesian statistics\n\n\nHierarchical Models\n\n\nCase study: election forecasting\n\n\n\n\n\n\n\nMon, Oct 16\n\n\n\nMidterm 1\n\n\nIncludes all topics covered by October 11.\n\n\n\n\n\nWed, Oct 18\n\n\n\nLinear Models\n\n\n\n\nRegression and correlation\n\n\nCase study: is height hereditary?\n\n\nBivariate normal distribution, conditional expectations, least squares estimates\n\n\n\n\n\n\n\n\n\nMon, Oct 23\n\n\n\nLinear Models\n\n\n\n\nMultivariable regression\n\n\nCase study: build a baseball team\n\n\n\n\n\n\n\n\n\nWed, Oct 25\n\n\n\nLinear Models\n\n\n\n\nMeasurement error models\n\n\nTreatment effect models \n\n\nCase study: does a high-fat diet increase weight in mice?\n\n\n\n\n\n\n\nMon, Oct 30\n\n\n\nLinear Models\n\n\n\n\nAssociation tests\n\n\nCorrelation is not causation\n\n\n\n\n\n\n\nWed, Nov 1\n\n\n\nHigh dimensional data\n\n\n\n\nMatrices in R \n\n\nCase study: handwritten digits\n\n\n\n\n\n\n\nFri, Nov 3 \n\n\n\nProblem set 2 due\n\n\nOne paragraph description of projects that includes what dataset will be used.\n\n\n\n\n\nMon, Nov 6\n\n\n\nHigh dimensional data\n\n\n\nDimension reduction: Linear algebra, distance, PCA\n\n\n\n\n\n\nWed, Nov 8\n\n\n\nHigh dimensional data\n\n\n\n\nDimension reduction continued\n\n\nCase study: gene expression differences between ethnic groups.\n\n\n\n\n\n\n\nFri, Nov 10 \n\n\n\nProject description due\n\n\nOne paragraph description of projects that includes what dataset will be used.\n\n\n\n\n\nMon, Nov 13\n\n\n\n\nHigh dimensional data\n\n\n\n\n\nRegularization\n\n\nCase study: Recommendations systems in  movie ratings\n\n\n\n\nMatrix factorization\n\n\n\n\n\n\n\nWed, Nov 15\n\n\n\nHigh dimensional data \n\n\n\n\nIntroduction, definition of concepts, accuracy, test, training and validation sets\n\n\nEvaluation metrics: ROC curves, precision recall curves\n\n\n\n\n\n\n\nMon, Nov 20\n\n\n\nMidterm 2\n\n\nIncludes topics covered until Nov 15.\n\n\n\n\n\nWed, Nov 22\n\n\n\nNo class\n\n\n Thanksgiving\n\n\n\n\n\nMon Nov 27\n\n\n\nMachine Learning\n\n\n\n\nSmoothing\n\n\nCase study: Death rates after natural disasters\n\n\n\n\n\n\n\nWed, Nov 29\n\n\n\nMachine Learning\n\n\n\n\nCross-Validation\n\n\ncaret package\n\n\n\n\n\n\n\nMon, Dec 4\n\n\n\nMachine Learning\n\n\n\n Example of algorithms \n\n\n\nCase study: reading handwritten digits\n\n\n\n\n\n\n\nWed, Dec 6 \n\n\n\nOther topics\n\n\n\nPossible topcis (open to student requests)\n\n\n\nShiny\n\n\nInteractive graphics: plotly\n\n\nAdvanced Quarto\n\n\nResearch topics\n\n\nLarge language models\n\n\nDeep learning\n\n\n\n\n\n\n\nFri Dec 8\n\n\n\nProblem set 3 due\n\n\n\n\n\n\n\nMon, Dec 11\n\n\n\nHelp with project\n\n\n\n \n\n\n\n\n\n\nWed, Dec 13\n\n\n\nHelp with project\n\n\n\n\n\n\n\nWed, Dec 15\n\n\n\nFinal project due"
  },
  {
    "objectID": "01-quarto.html#r-and-rstudio",
    "href": "01-quarto.html#r-and-rstudio",
    "title": "1  Quarto",
    "section": "1.1 R and RStudio",
    "text": "1.1 R and RStudio\nBefore introducing Quarto we need R installed. We highly recommend using RStudio as an IDE for this course. We will be using it in lectures.\n\n1.1.1 Installation\n\nInstall the latest version (4.3.1) of R\nInstall RStudio\n\n\n\n\nrstudio\n\n\n\n\n1.1.2 Basics\nLet’s try a few things together:\n\nOpen a new R script file\nLearn tab complete\nRun commands while editing scripts\nRun the entire script\nMake a plot\nChange options to never save workspace.\n\n\n\n1.1.3 Projects\n\nStart new project in exciting directory.\nStart new project in new directory.\nChange projects."
  },
  {
    "objectID": "01-quarto.html#markdown",
    "href": "01-quarto.html#markdown",
    "title": "1  Quarto",
    "section": "1.2 Markdown",
    "text": "1.2 Markdown\nStart a new Quarto.\n\n1.2.1 Type of editor\n\nSource - See the actual code (WYSIWYG).\nVisual - Partial preview of final document.\n\n\n\n1.2.2 The header\nAt the top you see:\n---\ntitle: \"Untitled\"\n---\nThe things between the --- is the YAML header.\nYou will see it used throughout the Quarto guide.\n\n\n1.2.3 Text formating\nitalics, bold, bold italics\nstrikethrough\ncode\n\n\n1.2.4 Headings\n# Header 1\n## Header 2\n### Header 3\nand so on\n\n\n1.2.5 Links\nJust the link: https://quarto.org/docs/guide/\nLinked text: This is the link to Quarto Guide\n\n\n1.2.6 Images\n\n\n\nFirst week of data science\n\n\nThe image can also be a local file.\n\n\n1.2.7 Lists\nBullets:\n\nbullet 1\n\nsub-bullet 1\nsub-bullet 2\n\nbullet 2\n\nOrdered list\n\nItem 1\nItem 2\n\n\n\n1.2.8 Equations\nInline: \\(Y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i\\)\nDisplay math:\n\\[\n\\mathbf{Y} = \\mathbf{X\\beta} + \\mathbf{\\varepsilon}\n\\]"
  },
  {
    "objectID": "01-quarto.html#computations",
    "href": "01-quarto.html#computations",
    "title": "1  Quarto",
    "section": "1.3 Computations",
    "text": "1.3 Computations\nThe main reason we use Quarto is because we can include code and execute the code when compiling the document. In R we refer to them as R chunks.\nTo add your own R chunks, you can type the characters above quickly with the key binding command-option-I on the Mac and Ctrl-Alt-I on Windows.\nThis applies to plots as well; the plot will be placed in that position. We can write something like this:\n\nx &lt;- 1\ny &lt;- 2\nx + y\n\n[1] 3\n\n\nBy default, the code will show up as well. To avoid having the code show up, you can use an argument, which are annotated with |# To avoid showing code in the final document, you can use the argument echo: FALSE. For example:\n\n\n[1] 3\n\n\nWe recommend getting into the habit of adding a label to the R code chunks. This will be very useful when debugging, among other situations. You do this by adding a descriptive word like this:\n\nx &lt;- 1\ny &lt;- 2\nx + y\n\n[1] 3\n\n\n\n1.3.1 Academic reports\nQuarto has many nice features that facilitates publishing academic reports in this guide\n\n\n1.3.2 Global execution options\nIf you want to apply an option globally, you can include in the header, under execute. For example adding the following line to the header make code not show up, by default:\nexecute:\n  echo: false\n\n\n1.3.3 More on markdown\nThere is a lot more you can do with R markdown. We highly recommend you continue learning as you gain more experience writing reports in R. There are many free resources on the internet including:\n\nRStudio’s tutorial: https://quarto.org/docs/get-started/hello/rstudio.html\nThe knitR book: https://yihui.name/knitr/\nPandoc’s Markdown in-depth documentation"
  },
  {
    "objectID": "01-quarto.html#sec-knitr",
    "href": "01-quarto.html#sec-knitr",
    "title": "1  Quarto",
    "section": "1.4 knitR",
    "text": "1.4 knitR\nWe use the knitR package to compile Quarto. The specific function used to compile is the knit function, which takes a file name as input. RStudio provides the Render button that makes it easier to compile the document.\nNote that the first time you click on the Render button, a dialog box may appear asking you to install packages you need. Once you have installed the packages, clicking Render will compile your Quarto file and the resulting document will pop up.\nThis particular example produces an html document which you can see in your working directory. To view it, open a terminal and list the files. You can open the file in a browser and use this to present your analysis. You can also produce a PDF or Microsoft document by changing:\nformat: html to format: pdf or format: docx. We can also produce documents that render on GitHub using format: gfm, which stands for GitHub flavored markdown, a convenient way to share your reports."
  },
  {
    "objectID": "01-quarto.html#exercises",
    "href": "01-quarto.html#exercises",
    "title": "1  Quarto",
    "section": "1.5 Exercises",
    "text": "1.5 Exercises\n\nWrite a Quarto document that defines variables \\(a=1, b=-1, c=-2\\) and print out the solutions to \\(f(x) = ax^2+bx+c=0\\). Do not report complex solutions, only real numbers.\nInclude a graph of \\(f(x)\\) versus \\(x\\) for \\(x \\in (-5,5)\\).\n\nThis is how you make a plot of a quadratic function:\n\na &lt;- 1 \nb &lt;- -1\nc &lt;- -2\nx &lt;- seq(-5, 5, length = 300)\nplot(x, a*x^2 + b*x + c, type = \"l\")\nabline(h = 0, lty = 2)\n\n\n\n\n\nGenerate a PDF report using knitr. Do not show the R code, only the solutions and explanations of what the reader is seeing.\nErase the PDF report and reproduce it but this time using \\(a=1, b=2, c=5\\).\nErase the PDF report and reproduce it but this time using \\(a=1, b=3, c=2\\).\nCreate an HTML page with the results for this last set of values, but this time showing the code."
  },
  {
    "objectID": "02-unix.html#naming-convention",
    "href": "02-unix.html#naming-convention",
    "title": "2  Unix",
    "section": "2.1 Naming convention",
    "text": "2.1 Naming convention\nIn general you want to name your files in a way that is related to their contents and specifies how they relate to other files. The Smithsonian Data Management Best Practices has “five precepts of file naming and organization” and they are:\n\n\n\nHave a distinctive, human-readable name that gives an indication of the content.\nFollow a consistent pattern that is machine-friendly.\nOrganize files into directories (when necessary) that follow a consistent pattern.\nAvoid repetition of semantic elements among file and directory names.\nHave a file extension that matches the file format (no changing extensions!)\n\n\n\nFor specific recommendations we highly recommend you follow The Tidyverse Style Guide1."
  },
  {
    "objectID": "02-unix.html#the-terminal",
    "href": "02-unix.html#the-terminal",
    "title": "2  Unix",
    "section": "2.2 The terminal",
    "text": "2.2 The terminal\n\necho \"Hello world\"\n\nHello world"
  },
  {
    "objectID": "02-unix.html#sec-filesystem",
    "href": "02-unix.html#sec-filesystem",
    "title": "2  Unix",
    "section": "2.3 The filesystem",
    "text": "2.3 The filesystem\n\n2.3.1 Directories and subdirectories\n\n\n\nfilesystem\n\n\n\n\n2.3.2 The home directory\n\n\n\n\n\n\nHome directory in Windows\n\n\n\n\n\n\n\nHome directory in MacOS\n\n\n\n\n\nThe structure on Windows looks something like this:\n\nAnd on MacOS something like this:"
  },
  {
    "objectID": "02-unix.html#working-directory",
    "href": "02-unix.html#working-directory",
    "title": "2  Unix",
    "section": "2.4 Working directory",
    "text": "2.4 Working directory\nThe working directory is the directly you are currently in. Later we will see that we can move to other directories using the command line. It’s similar to clicking on folders.\nYou can see your working directory like this:\n\npwd\n\n/Users/rafa/Documents/teaching/bst260/2023\n\n\nIn R we can use\n\ngetwd()\n\n[1] \"/Users/rafa/Documents/teaching/bst260/2023\""
  },
  {
    "objectID": "02-unix.html#sec-paths",
    "href": "02-unix.html#sec-paths",
    "title": "2  Unix",
    "section": "2.5 Paths",
    "text": "2.5 Paths\nThis string returned in previous command is full path to working directory.\nThe full path to your home directory is stored in an environment variable, discussed in more detail later:\n\necho $HOME\n\n/Users/rafa\n\n\nIn Unix, we use the shorthand ~ as a nickname for your home directory\nExample: the full path for docs (in image above) can be written like this ~/docs.\nMost terminals will show the path to your working directory right on the command line.\nExercise: Open a terminal window and see if the working directory is listed."
  },
  {
    "objectID": "02-unix.html#unix-commands",
    "href": "02-unix.html#unix-commands",
    "title": "2  Unix",
    "section": "2.6 Unix commands",
    "text": "2.6 Unix commands\n\n2.6.1 ls: Listing directory content\n\n\nls\n\n\n\n2.6.2 mkdir and rmdir: make and remove a directory\n\nmkdir projects\n\nIf you do this correctly, nothing will happen: no news is good news. If the directory already exists, you will get an error message and the existing directory will remain untouched.\nTo confirm that you created these directories, you can list the directories:\n\nls\n\nYou should see the directories we just created listed.\n\nmkdir docs teaching\n\nIf you made a mistake and need to remove the directory, you can use the command rmdir to remove it.\n\nmkdir junk\nrmdir junk\n\n\n\n2.6.3 cd: navigating the filesystem by changing directories\n\ncd projects\n\nTo check that the working directory changed, we can use a command we previously learned to see our location:\n\npwd"
  },
  {
    "objectID": "02-unix.html#autocomplete",
    "href": "02-unix.html#autocomplete",
    "title": "2  Unix",
    "section": "2.7 Autocomplete",
    "text": "2.7 Autocomplete\nIn Unix you can auto-complete by hitting tab. This means that we can type cd d then hit tab. Unix will either auto-complete if docs is the only directory/file starting with d or show you the options. Try it out! Using Unix without auto-complete will make it unbearable.\n\n2.7.1 cd continued\nGoing back one:\n\ncd ..\n\nGoing home:\n\ncd ~\n\nor simply:\n\ncd\n\nStating put (later we see why useful)\n\ncd .\n\nGoing far:\n\ncd /c/Users/yourusername/projects\n\nUsing relative paths:\n\ncd ../..\n\nGoing to previous working directory\n\ncd -"
  },
  {
    "objectID": "02-unix.html#practice",
    "href": "02-unix.html#practice",
    "title": "2  Unix",
    "section": "2.8 Practice",
    "text": "2.8 Practice\nLet’s explore some examples of navigating a filesystem using the command-line. Download and expand this file into a temporary directory and you will have the data struct in the following image.\n\n\n\nPractice file system\n\n\n\nSuppose our working directory is ~/projects, move to figs in project-1.\n\n\ncd project-1/figs\n\n\nNow suppose our working directory is ~/projects. Move to reports in docs in two different ways:\n\nThis is a relative path:\n\ncd ../docs/reports\n\nThe full path:\n\ncd ~/docs/reports ## assuming ~ is hometo\n\n\nSuppose we are in ~/projects/project-1/figs and want to change to ~/projects/project-2, show two different ways, one with relative path and one with full path.\n\nThis is with relative path\n\ncd ../../projects-2\n\nWith a full path\n\ncd ~/projects/proejcts-2 ## assuming home is ~"
  },
  {
    "objectID": "02-unix.html#more-unix-commands",
    "href": "02-unix.html#more-unix-commands",
    "title": "2  Unix",
    "section": "2.9 More Unix commands",
    "text": "2.9 More Unix commands\n\n2.9.1 mv: moving files\n\nmv path-to-file path-to-destination-directory\n\nFor example, if we want to move the file cv.tex from resumes to reports, you could use the full paths like this:\n\nmv ~/docs/resumes/cv.tex ~/docs/reports/\n\nYou can also use relative paths. So you could do this:\n\ncd ~/docs/resumes\nmv cv.tex ../reports/\n\nor this:\n\ncd ~/docs/reports/\nmv ../resumes/cv.tex ./\n\nWe can also use mv to change the name of a file.\n\ncd ~/docs/resumes\nmv cv.tex resume.tex\n\nWe can also combine the move and a rename. For example:\n\ncd ~/docs/resumes\nmv cv.tex ../reports/resume.tex\n\nAnd we can move entire directories. To move the resumes directory into reports, we do as follows:\n\nmv ~/docs/resumes ~/docs/reports/\n\nIt is important to add the last / to make it clear you do not want to rename the resumes directory to reports, but rather move it into the reports directory.\n\n\n2.9.2 cp: copying files\nThe command cp behaves similar to mv except instead of moving, we copy the file, meaning that the original file stays untouched.\n\n\n2.9.3 rm: removing files\nIn point-and-click systems, we remove files by dragging and dropping them into the trash or using a special click on the mouse. In Unix, we use the rm command.\n\n\n\n\n\n\nWarning\n\n\n\nUnlike throwing files into the trash, rm is permanent. Be careful!\n\n\nThe general way it works is as follows:\n\nrm filename\n\nYou can actually list files as well like this:\n\nrm filename-1 filename-2 filename-3\n\nYou can use full or relative paths. To remove directories, you will have to learn about arguments, which we do later.\n\n\n2.9.4 less: looking at a file\nOften you want to quickly look at the content of a file. If this file is a text file, the quickest way to do is by using the command less. To look a the file cv.tex, you do this:\n\ncd ~/docs/resumes\nless cv.tex \n\nTo exit the viewer, you type q. If the files are long, you can use the arrow keys to move up and down. There are many other keyboard commands you can use within less to, for example, search or jump pages."
  },
  {
    "objectID": "02-unix.html#sec-prep-project",
    "href": "02-unix.html#sec-prep-project",
    "title": "2  Unix",
    "section": "2.10 Preparing for a data science project",
    "text": "2.10 Preparing for a data science project\nWe are now ready to prepare a directory for a project. We will use the US murders project2 as an example.\nYou should start by creating a directory where you will keep all your projects. We recommend a directory called projects in your home directory. To do this you would type:\n\ncd ~\nmkdir projects\n\nOur project relates to gun violence murders so we will call the directory for our project murders. It will be a subdirectory in our projects directories. In the murders directory, we will create two subdirectories to hold the raw data and intermediate data. We will call these data and rda, respectively.\nOpen a terminal and make sure you are in the home directory:\n\ncd ~\n\nNow run the following commands to create the directory structure we want. At the end, we use ls and pwd to confirm we have generated the correct directories in the correct working directory:\n\ncd projects\nmkdir murders\ncd murders\nmkdir data rdas \nls\npwd\n\nNote that the full path of our murders dataset is ~/projects/murders.\nSo if we open a new terminal and want to navigate into that directory we type:\n\ncd projects/murders"
  },
  {
    "objectID": "02-unix.html#text-editors",
    "href": "02-unix.html#text-editors",
    "title": "2  Unix",
    "section": "2.11 Text editors",
    "text": "2.11 Text editors\nIn the course we will be using RStudio to edit files. But there will be situations in where this is not the most efficient approach. You might also need to write R code on a server that does not have RStudio installed. For this reason you need to learn to use a command-line text editors or terminal-based text editors. A key feature of these is that you can do everything you need on a terminal without the need for graphical interface. This is often necessary when using remote servers or computers you are not sitting in front off.\nCertainly! Command-line text editors are essential tools, especially for system administrators, developers, and other users who frequently work in a terminal environment. Here are some of the most popular command-line text editors:\n\nNano - Easy to use and beginner-friendly.\n\nFeatures: Simple interface, easy-to-use command prompts at the bottom of the screen, syntax highlighting.\n\nPico - Originally part of the Pine email client (Pico = PIne COmposer). It’s a simple editor and was widely used before Nano came around.\nVi or Vim - Vi is one of the oldest text editors and comes pre-installed on many UNIX systems. It is harder to use than Nano and Pico but is much more powerful. Vim is an enhanced version of Vi.\nEmacs - Another old and powerful text editor. It’s known for being extremely extensible.\n\nTo use these to edit a file you type, for example,\n\nnano filename"
  },
  {
    "objectID": "02-unix.html#advanced-unix",
    "href": "02-unix.html#advanced-unix",
    "title": "2  Unix",
    "section": "2.12 Advanced Unix",
    "text": "2.12 Advanced Unix\n\n2.12.1 Arguments\n\nrm -r directory-name\n\nall files, subdirectories, files in subdirectories, subdirectories in subdirectories, and so on, will be removed. This is equivalent to throwing a folder in the trash, except you can’t recover it. Once you remove it, it is deleted for good. Often, when you are removing directories, you will encounter files that are protected. In such cases, you can use the argument -f which stands for force.\nYou can also combine arguments. For instance, to remove a directory regardless of protected files, you type:\n\nrm -rf directory-name\n\n\n\n\n\n\n\nWarning\n\n\n\nRemember that once you remove there is no going back, so use this command very carefully.\n\n\nA command that is often called with argument is ls. Here are some examples:\n\nls -a \n\n\nls -l \n\nIt is often useful to see files in chronological order. For that we use:\n\nls -t \n\nand to reverse the order of how files are shown you can use:\n\nls -r \n\nWe can combine all these arguments to show more information for all files in reverse chronological order:\n\nls -lart \n\nEach command has a different set of arguments. In the next section, we learn how to find out what they each do.\n\n\n2.12.2 Getting help\n\nman ls\n\nor\n\nls --help\n\n\n\n2.12.3 Pipes\n\nman ls | less\n\nor in Git Bash:\n\nls --help | less \n\nThis is also useful when listing files with many files. We can type:\n\nls -lart | less \n\n\n\n2.12.4 Wild cards\n\nls *.html\n\nTo remove all html files in a directory, we would type:\n\nrm *.html\n\nThe other useful wild card is the ? symbol.\n\nrm file-???.html\n\nThis will only remove files with that format.\nWe can combine wild cards. For example, to remove all files with the name file-001 regardless of suffix, we can type:\n\nrm file-001.* \n\n\n\n\n\n\n\nWarning\n\n\n\nCombining rm with the * wild card can be dangerous. There are combinations of these commands that will erase your entire filesystem without asking “are you sure?”. Make sure you understand how it works before using this wild card with the rm command.**\n\n\n\n\n2.12.5 Environment variables\nEarlier we saw this:\n\necho $HOME \n\nYou can see them all by typing:\n\nenv\n\nYou can change some of these environment variables. But their names vary across different shells. We describe shells in the next section.\n\n\n2.12.6 Shells\n\necho $SHELL\n\nThe most common one is bash.\nOnce you know the shell, you can change environmental variables. In Bash Shell, we do it using export variable value. To change the path, described in more detail soon, type: (Don’t actually run this command though!)\n\nexport PATH = /usr/bin/\n\n\n\n2.12.7 Executables\n\n\nwhich git\n\nThat directory is probably full of program files. The directory /usr/bin usually holds many program files. If you type:\n\nls /usr/bin\n\nin your terminal, you will see several executable files.\nThere are other directories that usually hold program files. The Application directory in the Mac or Program Files directory in Windows are examples.\nTo see where your system looks:\n\necho $PATH\n\nyou will see a list of directories separated by :. The directory /usr/bin is probably one of the first ones on the list.\nIf your command is called my-ls, you can type:\n\n./my-ls\n\nOnce you have mastered the basics of Unix, you should consider learning to write your own executables as they can help alleviate repetitive work.\n\n\n2.12.8 Permissions and file types\nIf you type:\n\nls -l\n\nAt the beginning, you will see a series of symbols like this -rw-r--r--. This string indicates the type of file: regular file -, directory d, or executable x. This string also indicates the permission of the file: is it readable? writable? executable? Can other users on the system read the file? Can other users on the system edit the file? Can other users execute if the file is executable? This is more advanced than what we cover here, but you can learn much more in a Unix reference book.\n\n\n2.12.9 Commands you should learn\n\ncurl - download data from the internet.\ntar - archive files and subdirectories of a directory into one file.\nssh - connect to another computer.\nfind - search for files by filename in your system.\ngrep - search for patterns in a file.\nawk/sed - These are two very powerful commands that permit you to find specific strings in files and change them.\nln - create a symbolic link. We do not recommend its use, but you should be familiar with it."
  },
  {
    "objectID": "02-unix.html#resources",
    "href": "02-unix.html#resources",
    "title": "2  Unix",
    "section": "2.13 Resources",
    "text": "2.13 Resources\nTo get started.\n\nhttps://www.codecademy.com/learn/learn-the-command-line\nhttps://www.edx.org/course/introduction-linux-linuxfoundationx-lfs101x-1\nhttps://www.coursera.org/learn/unix"
  },
  {
    "objectID": "02-unix.html#exercises",
    "href": "02-unix.html#exercises",
    "title": "2  Unix",
    "section": "2.14 Exercises",
    "text": "2.14 Exercises\nYou are not allowed to use RStudio or point and click for any of the exercises below. Open a text file called commands.txt using a text editor and keep a log of the commands you use in the exercises below. If you want to take notes, you can use # to distinguish notes from commands.\n\nDecide on a directory where you will save your class materials. Navigate into the directory using a full path.\nMake a directory called project-1 and cd into that directory.\nMake directors called data: data, rdas, code, and docs.\nUse curl or wget to download the file https://raw.githubusercontent.com/rafalab/dslabs/master/inst/extdata/murders.csv and store it in rdas.\nCreate a R file in the code directory called code-1.R, write the following code in the file so that if the working directory is code it reads in the csv file you just downloaded. Use only relative paths.\n\n\nfilename &lt;- \"\"\ndat &lt;- read.csv(filename)\n\n\nAdd the following line to your R code so that it saves the file to the rdas directory. Use only relative paths.\n\n\nout &lt;- \"\"\ndat &lt;- save(dat, file = out)\n\n\nCreate a file code-2.R in the code directory. Use the following command to add a line to the file.\n\necho \"load('../rdas/murders.rda')\" &gt; code/code-2.R\nCheck to see if the line of code as added without opening a text editor.\n\nNavigate to the code directory and list all the files ending in .R.\nNavigate to the project-1 directory. Without navigating away, change the name of code-1.R to import.R, but keep the file in the same directory.\nChange the name of the project directory to murders. Describe what you have to change so the R script sill does the right thing and how this would be different if you had used full paths.\nBonus : Navigate to the murders directory. Read the man page for the find function. Use find to list all the files ending in .R."
  },
  {
    "objectID": "02-unix.html#footnotes",
    "href": "02-unix.html#footnotes",
    "title": "2  Unix",
    "section": "",
    "text": "https://style.tidyverse.org/↩︎\nhttps://github.com/rairizarry/murders↩︎"
  },
  {
    "objectID": "03-git.html#why-use-git-and-github",
    "href": "03-git.html#why-use-git-and-github",
    "title": "3  Git and GitHub",
    "section": "3.1 Why use Git and GitHub?",
    "text": "3.1 Why use Git and GitHub?\n\nSharing.\nCollaborating.\nVersion control.\n\nWe focus on the sharing aspects of Git and GitHub, but introduce some of the basics that permit you to collaborate and version control."
  },
  {
    "objectID": "03-git.html#what-is-git",
    "href": "03-git.html#what-is-git",
    "title": "3  Git and GitHub",
    "section": "3.2 What is Git?",
    "text": "3.2 What is Git?\n\n\n\nArt by: Allison Horst"
  },
  {
    "objectID": "03-git.html#what-is-github",
    "href": "03-git.html#what-is-github",
    "title": "3  Git and GitHub",
    "section": "3.3 What is GitHub?",
    "text": "3.3 What is GitHub?\nBasically, it’s a service that hosts the remote repository (repo) on the web. This facilitates collaboration and sharing greatly.\nThere many other features such as\n\na recognition system: reward, badges and stars, for example.\nhosting web pages, like the class notes for example.\nforks and pull requests,\nissue tracking\nautomation tools\n\nIt has been describes a social network for software developers.\nThe main tool behind GitHub, is Git.\nSimilar to how to how main tool behind RStudio, is R."
  },
  {
    "objectID": "03-git.html#github-accounts",
    "href": "03-git.html#github-accounts",
    "title": "3  Git and GitHub",
    "section": "3.4 GitHub accounts",
    "text": "3.4 GitHub accounts\nOnce you have a GitHub account, you are ready to connect Git and RStudio to this account.\nA first step is to let Git know who we are. This will make it easier to connect with GitHub. We start by opening a terminal window in RStudio (remember you can get one through Tools in the menu bar). Now we use the git config command to tell Git who we are. We will type the following two commands in our terminal window:\ngit config --global user.name \"Your Name\"\ngit config --global user.mail \"your@email.com\"\nConsider adding a profile README.md. Instructions are here\nLooks like this"
  },
  {
    "objectID": "03-git.html#repositories",
    "href": "03-git.html#repositories",
    "title": "3  Git and GitHub",
    "section": "3.5 Repositories",
    "text": "3.5 Repositories\nYou are now ready to create a GitHub repository (repo). This will be your remote repo.\nThe general idea is that you will have at least two copies of your code: one on your computer and one on GitHub. If you add collaborators to this repo, then each will have a copy on their computer. The GitHub copy is usually considered the main (previously called master) copy that each collaborator syncs to. Git will help you keep all the different copies synced.\nLet’s go make one on GitHub…\nThen create a directory on your computer, this will be the local repo, and connect it to the Github repository.\nFirst copy and paste the location of your git repository\nIt should look something like this:\nhttps://github.com/your-username/your-repo-name.git\ngit init\ngit remote add origin &lt;remote-url&gt;\nNow the two are connected."
  },
  {
    "objectID": "03-git.html#sec-git-overview",
    "href": "03-git.html#sec-git-overview",
    "title": "3  Git and GitHub",
    "section": "3.6 Overview of Git",
    "text": "3.6 Overview of Git\nThe main actions in Git are to:\n\npull changes from the remote repo, in this case the GitHub repo\nadd files, or as we say in the Git lingo stage files\ncommit changes to the local repo\npush changes to the remote repo, in our case the GitHub repo\n\n\n\n\nFrom Meme Git Compilation by Lulu Ilmaknun Qurotaini\n\n\n\n3.6.1 The four areas of Git\n\n\n\n3.6.2 Status\n\ngit status filename\n\n\n3.6.3 Add\nUse git add to move put file to staging area.\n\ngit add &lt;filename&gt;\ngit status &lt;filename&gt;\n\n\n3.6.4 Commit\nUse\ngit commit -m \"must add comment\"\nto move all the added files to the local repository. This file is now tracked and a copy of this version is kept going forward… this is like adding V1 to your filename.\nYou can commit files directly without using add by explicitely writing the files at the end of the commit:\ngit commit -m \"must add comment\" &lt;filename&gt;\n\n\n\n3.6.5 Push\nTo move to upstream repo we use\ngit push -u origin main\nThe -u flag sets the upstream, so in the future, you can simply use git push to push changes. So going forward we can just type:\ngit push\nHere we need to be careful as if collaborating this will affect the work of others. It might also create a conflict.\n\n\n\n3.6.6 Fetch\nTo update our local repository to the remote one we use\ngit fetch\n\n\n\n3.6.7 Merge\nOnce we are sure this is good, we can merge with our local files\ngit merge\n\n\n\n3.6.8 Pull\nIt is common to want to just skip the fetch step and just update everything. For this we use\ngit pull\n\n\n\n3.6.9 Checkout\n If you want to pull down a specific file you from the remote repo you can use:\ngit checkout filename\nBut if you have a newer version in your local repository this will create a conflict. If you are sure you want to get rid of your local copy you can remove and then checkout.\nYou can also use checkout to pull older version:\ngit checkout &lt;commit-id&gt; &lt;filename&gt;\nYou can get the commit-id either on the GitHub webpage or using\ngit log filename\n\n\n\n\n\n\nNote\n\n\n\nIf you are asked for passwords when connecting or pushing things to you want to read this and avoid this. It will be impossible to use if you have to enter a password each time you push."
  },
  {
    "objectID": "03-git.html#branches",
    "href": "03-git.html#branches",
    "title": "3  Git and GitHub",
    "section": "3.7 Branches",
    "text": "3.7 Branches\nGit can be even more complex. We can have several branches. These are useful for working in parallel or testing stuff out that might not make the main repo.\n\n\n\nArt by: Allison Horst\n\n\nWe wont go over this. But you should at least now these three commands\ngit remote -v\ngit brach"
  },
  {
    "objectID": "03-git.html#clone",
    "href": "03-git.html#clone",
    "title": "3  Git and GitHub",
    "section": "3.8 Clone",
    "text": "3.8 Clone\n\nIf you\ngit clone &lt;repo-url&gt;\npwd\nmkdir git-example\ncd git-example\ngit clone https://github.com/rairizarry/murders.git\ncd murders"
  },
  {
    "objectID": "03-git.html#using-git-in-rstudio",
    "href": "03-git.html#using-git-in-rstudio",
    "title": "3  Git and GitHub",
    "section": "3.9 Using Git in RStudio",
    "text": "3.9 Using Git in RStudio\nGo to file, new project, version control, and follow the instructions. Then notice the Git tab.\n For more memes see Meme Git Compilation by Lulu Ilmaknun"
  },
  {
    "objectID": "04-r-basics.html#packages",
    "href": "04-r-basics.html#packages",
    "title": "4  R Basics",
    "section": "4.1 Packages",
    "text": "4.1 Packages\nUse install.packages to install the dslabs package.\nTryout the following functions: sessionInfo, installed.packages"
  },
  {
    "objectID": "04-r-basics.html#prebuilt-functions",
    "href": "04-r-basics.html#prebuilt-functions",
    "title": "4  R Basics",
    "section": "4.2 Prebuilt functions",
    "text": "4.2 Prebuilt functions\nMuch of what we do in R is called prebuilt functions. Today we are using: ls, rm, library, search, factor, list, exists, str, typeof, class and maybe more.\nYou can see the code for a function by typing it without the parenthesis:\nTry this:\n\nls"
  },
  {
    "objectID": "04-r-basics.html#help-system",
    "href": "04-r-basics.html#help-system",
    "title": "4  R Basics",
    "section": "4.3 Help system",
    "text": "4.3 Help system\nIn R you can use ? or help to learn more about functions.\nYou can learn about function using\nhelp(\"ls\")\nor\n?ls"
  },
  {
    "objectID": "04-r-basics.html#the-workspace",
    "href": "04-r-basics.html#the-workspace",
    "title": "4  R Basics",
    "section": "4.4 The workspace",
    "text": "4.4 The workspace\nDefine a variable.\nUse ls to see if it’s there. Also take a look at the Environment tab in RStudio.\nUse rm to remove the variable you defined."
  },
  {
    "objectID": "04-r-basics.html#variable-name-convention",
    "href": "04-r-basics.html#variable-name-convention",
    "title": "4  R Basics",
    "section": "4.5 Variable name convention",
    "text": "4.5 Variable name convention\nA nice convention to follow is to use meaningful words that describe what is stored, use only lower case, and use underscores as a substitute for spaces.\nFor more we recommend this guide."
  },
  {
    "objectID": "04-r-basics.html#data-types",
    "href": "04-r-basics.html#data-types",
    "title": "4  R Basics",
    "section": "4.6 Data types",
    "text": "4.6 Data types\nThe main data types in R are:\n\nOne dimensional vectors: numeric, integer, logical, complex, characters.\nFactors\nLists: this includes data frames\nArrays: Matrices are the most widely used\nDate and time\ntibble\nS4 objects\n\nMany errors in R come from confusing data types. Let’s learn what these data types are and useful tools to help us.\nstr stands for structure, gives us information about an object.\ntypeof gives you the basic data type of the object. It reveals the lower-level, more fundamental type of an object in R’s memory.\nclass This function returns the class attribute of an object. The class of an object is essentially type_of at a higher, often user-facing level.\n\nlibrary(dslabs)\n\n\ntypeof(murders)\n\n[1] \"list\"\n\n\n\nclass(murders)\n\n[1] \"data.frame\"\n\n\n\nstr(murders)\n\n'data.frame':   51 obs. of  5 variables:\n $ state     : chr  \"Alabama\" \"Alaska\" \"Arizona\" \"Arkansas\" ...\n $ abb       : chr  \"AL\" \"AK\" \"AZ\" \"AR\" ...\n $ region    : Factor w/ 4 levels \"Northeast\",\"South\",..: 2 4 4 2 4 4 1 2 2 2 ...\n $ population: num  4779736 710231 6392017 2915918 37253956 ...\n $ total     : num  135 19 232 93 1257 ..."
  },
  {
    "objectID": "04-r-basics.html#data-frames",
    "href": "04-r-basics.html#data-frames",
    "title": "4  R Basics",
    "section": "4.7 Data frames",
    "text": "4.7 Data frames\nDate frames are the most common class used in data analysis. It is like a spreadsheet. Rows represents observations and columns variables. Each variable can be a different data type.\nYou can add columns like this:\n\nmurders$pop_rank &lt;- rank(murders$population)\nhead(murders)\n\n       state abb region population total pop_rank\n1    Alabama  AL  South    4779736   135       29\n2     Alaska  AK   West     710231    19        5\n3    Arizona  AZ   West    6392017   232       36\n4   Arkansas  AR  South    2915918    93       20\n5 California  CA   West   37253956  1257       51\n6   Colorado  CO   West    5029196    65       30\n\n\nYou can access columns with the $\n\nmurders$population\n\n [1]  4779736   710231  6392017  2915918 37253956  5029196  3574097   897934\n [9]   601723 19687653  9920000  1360301  1567582 12830632  6483802  3046355\n[17]  2853118  4339367  4533372  1328361  5773552  6547629  9883640  5303925\n[25]  2967297  5988927   989415  1826341  2700551  1316470  8791894  2059179\n[33] 19378102  9535483   672591 11536504  3751351  3831074 12702379  1052567\n[41]  4625364   814180  6346105 25145561  2763885   625741  8001024  6724540\n[49]  1852994  5686986   563626\n\n\nbut also []\n\nmurders[1:5,]\n\n       state abb region population total pop_rank\n1    Alabama  AL  South    4779736   135       29\n2     Alaska  AK   West     710231    19        5\n3    Arizona  AZ   West    6392017   232       36\n4   Arkansas  AR  South    2915918    93       20\n5 California  CA   West   37253956  1257       51\n\n\n\nmurders[1:5, 1:2]\n\n       state abb\n1    Alabama  AL\n2     Alaska  AK\n3    Arizona  AZ\n4   Arkansas  AR\n5 California  CA\n\n\n\nmurders[1:5, c(\"state\", \"abb\")]\n\n       state abb\n1    Alabama  AL\n2     Alaska  AK\n3    Arizona  AZ\n4   Arkansas  AR\n5 California  CA"
  },
  {
    "objectID": "04-r-basics.html#with",
    "href": "04-r-basics.html#with",
    "title": "4  R Basics",
    "section": "4.8 with",
    "text": "4.8 with\nThe function with let’s us use the column names as objects:\n\nwith(murders, length(state))\n\n[1] 51"
  },
  {
    "objectID": "04-r-basics.html#vectors",
    "href": "04-r-basics.html#vectors",
    "title": "4  R Basics",
    "section": "4.9 Vectors",
    "text": "4.9 Vectors\nThe columns of data frames are one dimensional (atomic) vectors.\nHere is an example:\n\nlength(murders$population)\n\n[1] 51\n\n\nHow to create vectors:\n\nx &lt;- c(\"b\", \"s\", \"t\", \" \", \"2\", \"6\", \"0\")\n\nSequences are particularly useful:\n\nseq(1, 10)\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\n\nseq(1, 9, 2)\n\n[1] 1 3 5 7 9\n\n\n\n1:10\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\n\nseq_along(x)\n\n[1] 1 2 3 4 5 6 7"
  },
  {
    "objectID": "04-r-basics.html#factors",
    "href": "04-r-basics.html#factors",
    "title": "4  R Basics",
    "section": "4.10 Factors",
    "text": "4.10 Factors\nOne key data type distinction is factors versus characters:\n\ntypeof(murders$state)\n\n[1] \"character\"\n\ntypeof(murders$region)\n\n[1] \"integer\"\n\n\nFactors store levels and then the label of each level. They are very useful for categorical data.\n\nx &lt;- murders$region\nlevels(x)\n\n[1] \"Northeast\"     \"South\"         \"North Central\" \"West\"         \n\n\n\n4.10.1 Categories based on strata\nThe function cut is useful for converting numbers into categories\n\nwith(murders, cut(population, \n                  c(0, 10^6, 10^7, Inf)))\n\n [1] (1e+06,1e+07] (0,1e+06]     (1e+06,1e+07] (1e+06,1e+07] (1e+07,Inf]  \n [6] (1e+06,1e+07] (1e+06,1e+07] (0,1e+06]     (0,1e+06]     (1e+07,Inf]  \n[11] (1e+06,1e+07] (1e+06,1e+07] (1e+06,1e+07] (1e+07,Inf]   (1e+06,1e+07]\n[16] (1e+06,1e+07] (1e+06,1e+07] (1e+06,1e+07] (1e+06,1e+07] (1e+06,1e+07]\n[21] (1e+06,1e+07] (1e+06,1e+07] (1e+06,1e+07] (1e+06,1e+07] (1e+06,1e+07]\n[26] (1e+06,1e+07] (0,1e+06]     (1e+06,1e+07] (1e+06,1e+07] (1e+06,1e+07]\n[31] (1e+06,1e+07] (1e+06,1e+07] (1e+07,Inf]   (1e+06,1e+07] (0,1e+06]    \n[36] (1e+07,Inf]   (1e+06,1e+07] (1e+06,1e+07] (1e+07,Inf]   (1e+06,1e+07]\n[41] (1e+06,1e+07] (0,1e+06]     (1e+06,1e+07] (1e+07,Inf]   (1e+06,1e+07]\n[46] (0,1e+06]     (1e+06,1e+07] (1e+06,1e+07] (1e+06,1e+07] (1e+06,1e+07]\n[51] (0,1e+06]    \nLevels: (0,1e+06] (1e+06,1e+07] (1e+07,Inf]\n\n\n\nmurders$size &lt;- cut(murders$population, c(0, 10^6, 10^7, Inf), \n            labels = c(\"small\", \"medium\", \"large\"))\nmurders[1:6,c(\"state\", \"size\")]\n\n       state   size\n1    Alabama medium\n2     Alaska  small\n3    Arizona medium\n4   Arkansas medium\n5 California  large\n6   Colorado medium\n\n\n\n\n4.10.2 changing levels\nYou can change the levels (this will come in handy when we learn linear models)\nOrder levels alphabetically:\n\nfactor(x, levels = sort(levels(murders$region)))\n\n [1] South         West          West          South         West         \n [6] West          Northeast     South         South         South        \n[11] South         West          West          North Central North Central\n[16] North Central North Central South         South         Northeast    \n[21] South         Northeast     North Central North Central South        \n[26] North Central West          North Central West          Northeast    \n[31] Northeast     West          Northeast     South         North Central\n[36] North Central South         West          Northeast     Northeast    \n[41] South         North Central South         South         West         \n[46] Northeast     South         West          South         North Central\n[51] West         \nLevels: North Central Northeast South West\n\n\nMake west the first level:\n\nx &lt;- relevel(x, ref = \"West\")\n\nOrder levels by population size:\n\nx &lt;- reorder(murders$region, murders$population, sum)\n\nFactors are more efficient:\n\nx &lt;- sample(murders$state[c(5,33,44)], 10^7, replace = TRUE)\ny &lt;- factor(x)\nobject.size(x)\n\n80000232 bytes\n\nobject.size(y)\n\n40000648 bytes\n\n\n\nsystem.time({x &lt;- tolower(x)})\n\n   user  system elapsed \n  1.441   0.011   1.452 \n\n\nExercise: How can we make this go much faster?\n\nsystem.time({levels(y) &lt;- tolower(levels(y))})\n\n   user  system elapsed \n  0.019   0.003   0.022 \n\n\nFactors can be confusing:\n\nx &lt;- factor(c(\"3\",\"2\",\"1\"), levels = c(\"3\",\"2\",\"1\"))\nas.numeric(x)\n\n[1] 1 2 3\n\n\n\nx[1]\n\n[1] 3\nLevels: 3 2 1\n\nlevels(x[1])\n\n[1] \"3\" \"2\" \"1\"\n\ntable(x[1])\n\n\n3 2 1 \n1 0 0 \n\nz &lt;- x[1]\nz &lt;- droplevels(z)\n\n\nx[1] &lt;- \"4\"\n\nWarning in `[&lt;-.factor`(`*tmp*`, 1, value = \"4\"): invalid factor level, NA\ngenerated\n\nx\n\n[1] &lt;NA&gt; 2    1   \nLevels: 3 2 1"
  },
  {
    "objectID": "04-r-basics.html#nas",
    "href": "04-r-basics.html#nas",
    "title": "4  R Basics",
    "section": "4.11 NAs",
    "text": "4.11 NAs\nNA stands for not available. We will see many NAs if we analyze data generally.\n\nx &lt;- as.numeric(\"a\")\n\nWarning: NAs introduced by coercion\n\n\n\nis.na(x)\n\n[1] TRUE\n\n\n\nis.na(\"a\")\n\n[1] FALSE\n\n\n\n1 + 2 + NA\n\n[1] NA\n\n\nWhen used with logicals behaves like FALSE\n\nTRUE & NA\n\n[1] NA\n\nTRUE | NA\n\n[1] TRUE\n\n\nBut is is not FALSE. Try this:\n\nif (NA) print(1) else print(0)\n\nA related constant is NaN which stands for not a number. It is a numeric that is not a number.\n\nclass(0/0)\n\n[1] \"numeric\"\n\nsqrt(-1)\n\nWarning in sqrt(-1): NaNs produced\n\n\n[1] NaN\n\nlog(-1)\n\nWarning in log(-1): NaNs produced\n\n\n[1] NaN\n\n0/0\n\n[1] NaN"
  },
  {
    "objectID": "04-r-basics.html#coercing",
    "href": "04-r-basics.html#coercing",
    "title": "4  R Basics",
    "section": "4.12 coercing",
    "text": "4.12 coercing\nWhen you do something nonsensical with data types, R tries to figure out what you mean. This can cause confusion and unnoticed errors. So it’s important to understand how and when it happens. Here are some examples:\n\ntypeof(1L)\n\n[1] \"integer\"\n\ntypeof(1)\n\n[1] \"double\"\n\ntypeof(1 + 1L)\n\n[1] \"double\"\n\n\n\nc(\"a\", 1, 2)\n\n[1] \"a\" \"1\" \"2\"\n\n\n\nTRUE + FALSE\n\n[1] 1\n\n\n\nfactor(\"a\") == \"a\"\n\n[1] TRUE\n\nidentical(factor(\"a\"), \"a\")\n\n[1] FALSE\n\n\nYou want to avoid automatic coercion and instead explicitly do it. Most coercion functions start with as.\n\nx &lt;- factor(c(\"a\",\"b\",\"b\",\"c\"))\nas.character(x)\n\n[1] \"a\" \"b\" \"b\" \"c\"\n\nas.numeric(x)\n\n[1] 1 2 2 3\n\n\n\nx &lt;- c(\"12323\", \"12,323\")\nas.numeric(x)\n\nWarning: NAs introduced by coercion\n\n\n[1] 12323    NA\n\nreadr::parse_guess(x)\n\n[1] 12323 12323"
  },
  {
    "objectID": "04-r-basics.html#lists",
    "href": "04-r-basics.html#lists",
    "title": "4  R Basics",
    "section": "4.13 lists",
    "text": "4.13 lists\nData frames are a type of list. List permit components of different types and, unlike data frames, length\n\nx &lt;- list(name = \"John\", id = 112, grades = c(95, 87, 92))\n\nYou can access components in different ways:\n\nx$name\n\n[1] \"John\"\n\nx[[1]]\n\n[1] \"John\"\n\nx[[\"name\"]]\n\n[1] \"John\""
  },
  {
    "objectID": "04-r-basics.html#matrics",
    "href": "04-r-basics.html#matrics",
    "title": "4  R Basics",
    "section": "4.14 matrics",
    "text": "4.14 matrics\nMatrices are another widely used data type. They are similar to data frames except all entries need to be of the same type.\nWe will learn more about matrices in the High Dimensional data Analysis part of the class."
  },
  {
    "objectID": "04-r-basics.html#functions",
    "href": "04-r-basics.html#functions",
    "title": "4  R Basics",
    "section": "4.15 functions",
    "text": "4.15 functions\nYou can define your own function. The form is like this:\n\nf &lt;- function(x, y, z = 0){\n  ### do calculations with x, y, z to compute object\n  ## return(object)\n}\n\nHere is an example of a function that sums \\(1,2,\\dots,n\\)\n\ns &lt;- function(n){\n   return(sum(1:n))\n}"
  },
  {
    "objectID": "04-r-basics.html#lexical-scope",
    "href": "04-r-basics.html#lexical-scope",
    "title": "4  R Basics",
    "section": "4.16 Lexical scope",
    "text": "4.16 Lexical scope\n\nf &lt;- function(x){\n  cat(\"y is\", y,\"\\n\")\n  y &lt;- x\n  cat(\"y is\", y,\"\\n\")\n  return(y)\n}\ny &lt;- 2\nf(3)\n\ny is 2 \ny is 3 \n\n\n[1] 3\n\ny &lt;- f(3)\n\ny is 2 \ny is 3 \n\ny\n\n[1] 3"
  },
  {
    "objectID": "04-r-basics.html#namespaces",
    "href": "04-r-basics.html#namespaces",
    "title": "4  R Basics",
    "section": "4.17 Namespaces",
    "text": "4.17 Namespaces\nLook at this function.\n\nfilter\nlibrary(dplyr)\nfilter\n\nNote this is just the Global Environment.\nUse search to see other environments.\nNote all the functions in stats\nYou can explicitly say which you want:\n\nstats::filter\ndplyr::filter\n\nTry to understand this example:\n\nexists(\"murders\")\n\n[1] TRUE\n\nlibrary(dslabs)\nexists(\"murders\")\n\n[1] TRUE\n\nmurders &lt;- murders\nmurders2 &lt;- murders\nrm(murders)\nexists(\"murders\")\n\n[1] TRUE\n\ndetach(\"package:dslabs\")\nexists(\"murders\")\n\n[1] FALSE\n\nexists(\"murders2\")\n\n[1] TRUE"
  },
  {
    "objectID": "04-r-basics.html#object-oriented-programming",
    "href": "04-r-basics.html#object-oriented-programming",
    "title": "4  R Basics",
    "section": "4.18 object oriented programming",
    "text": "4.18 object oriented programming\nR uses object oriented programming. It uses to approaches referred to as S3 and S4. The original S3 is more common.\nWhat does this mean?\n\nclass(co2)\n\n[1] \"ts\"\n\nplot(co2)\n\n\n\n\n\nplot(as.numeric(co2))\n\n\n\n\nSee the difference? The first one actually calls the function\n\nplot.ts\n\nNotice all the plot functions that start with plot.\nThe function plot will call different functions depending on the class of the arguments:\n\nplot\n\nfunction (x, y, ...) \nUseMethod(\"plot\")\n&lt;bytecode: 0x11b166860&gt;\n&lt;environment: namespace:base&gt;"
  },
  {
    "objectID": "04-r-basics.html#exercises",
    "href": "04-r-basics.html#exercises",
    "title": "4  R Basics",
    "section": "4.19 Exercises",
    "text": "4.19 Exercises\n\nWhat is the sum of the first 100 positive integers? The formula for the sum of integers \\(1\\) through \\(n\\) is \\(n(n+1)/2\\). Define \\(n=100\\) and then use R to compute the sum of \\(1\\) through \\(100\\) using the formula. What is the sum?\n\n\nn &lt;- 100\nn*(n + 1) / 2\n\n[1] 5050\n\n\n\nNow use the same formula to compute the sum of the integers from 1 through 1,000.\n\n\nn &lt;- 1000\nn*(n + 1) / 2\n\n[1] 500500\n\n\n\nNow use the functions seq and sum to compute the sum with R for any n, rather than a formula.\n\n\nn &lt;- 100\nx &lt;- seq(1, 100)\nsum(x)\n\n[1] 5050\n\n\n\nIn math and programming, we say that we evaluate a function when we replace the argument with a given number. So if we type sqrt(4), we evaluate the sqrt function. In R, you can evaluate a function inside another function. The evaluations happen from the inside out. Use one line of code to compute the log, in base 10, of the square root of 100.\n\n\nlog(sqrt(100), base = 10)\n\n[1] 1\n\nlog10(sqrt(100))\n\n[1] 1\n\n\n\nMake sure the US murders dataset is loaded. Use the function str to examine the structure of the murders object. What are the column names used by the data frame for these five variables?\n\n\nlibrary(dslabs)\nstr(murders)\n\n'data.frame':   51 obs. of  5 variables:\n $ state     : chr  \"Alabama\" \"Alaska\" \"Arizona\" \"Arkansas\" ...\n $ abb       : chr  \"AL\" \"AK\" \"AZ\" \"AR\" ...\n $ region    : Factor w/ 4 levels \"Northeast\",\"South\",..: 2 4 4 2 4 4 1 2 2 2 ...\n $ population: num  4779736 710231 6392017 2915918 37253956 ...\n $ total     : num  135 19 232 93 1257 ..."
  },
  {
    "objectID": "05-vectorization.html#arithmetics",
    "href": "05-vectorization.html#arithmetics",
    "title": "5  Vectorization",
    "section": "5.1 Arithmetics",
    "text": "5.1 Arithmetics\n\nheights &lt;- c(69, 62, 66, 70, 70, 73, 67, 73, 67, 70)\n\nConvert to meters:\n\nheights * 2.54 / 100\n\n [1] 1.7526 1.5748 1.6764 1.7780 1.7780 1.8542 1.7018 1.8542 1.7018 1.7780\n\n\nDifference from the average:\n\navg &lt;- mean(heights)\nheights - avg \n\n [1]  0.3 -6.7 -2.7  1.3  1.3  4.3 -1.7  4.3 -1.7  1.3\n\n\nExercise: compute the height in standardized units\n\ns &lt;- sd(heights)\n(heights - avg) / s\n\n [1]  0.08995503 -2.00899575 -0.80959530  0.38980515  0.38980515  1.28935548\n [7] -0.50974519  1.28935548 -0.50974519  0.38980515\n\n# can also use scale(heights)\n\nIf it’s two vectors, it does it component wise:\n\nheights &lt;- c(69, 62, 66, 70, 70, 73, 67, 73, 67, 70)\nerror &lt;- rnorm(length(heights), 0, 0.1)\nheights + error\n\n [1] 69.22731 61.96707 65.91319 69.97864 70.05011 73.06697 66.98434 72.99172\n [9] 67.06568 69.73234\n\n\nExercise:\nAdd a column to the murders dataset with the murder rate in per 100,000.\n\nlibrary(dslabs)\nmurders$rate &lt;- with(murders, total / population * 10^5)"
  },
  {
    "objectID": "05-vectorization.html#functions-that-vectorize",
    "href": "05-vectorization.html#functions-that-vectorize",
    "title": "5  Vectorization",
    "section": "5.2 Functions that vectorize",
    "text": "5.2 Functions that vectorize\nMost arithmetic functions work on vectors\n\nx &lt;- 1:10\nsqrt(x)\n\n [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751 2.828427\n [9] 3.000000 3.162278\n\nlog(x)\n\n [1] 0.0000000 0.6931472 1.0986123 1.3862944 1.6094379 1.7917595 1.9459101\n [8] 2.0794415 2.1972246 2.3025851\n\n2^x\n\n [1]    2    4    8   16   32   64  128  256  512 1024\n\n\nNote that the conditional function if-else does not vectorize. A particularly useful function is a vectorized version ifelse. Here is an example:\n\na &lt;- c(0, 1, 2, -4, 5)\nifelse(a &gt; 0, 1/a, NA)\n\n[1]  NA 1.0 0.5  NA 0.2\n\n\nOther conditional functions, such as any and all, do vectorize."
  },
  {
    "objectID": "05-vectorization.html#indexing",
    "href": "05-vectorization.html#indexing",
    "title": "5  Vectorization",
    "section": "5.3 Indexing",
    "text": "5.3 Indexing\nVectorization also works for logical relationships:\n\nind &lt;- murders$population &lt; 10^6\n\nYou can subset a vector using these:\n\nmurders$state[ind]\n\n[1] \"Alaska\"               \"Delaware\"             \"District of Columbia\"\n[4] \"Montana\"              \"North Dakota\"         \"South Dakota\"        \n[7] \"Vermont\"              \"Wyoming\"             \n\n\nYou can also use vectorization to apply logical operators:\n\nind &lt;- murders$population &lt; 10^6 & murders$region == \"West\"\nmurders$state[ind]\n\n[1] \"Alaska\"  \"Montana\" \"Wyoming\""
  },
  {
    "objectID": "05-vectorization.html#split",
    "href": "05-vectorization.html#split",
    "title": "5  Vectorization",
    "section": "5.4 split",
    "text": "5.4 split\nSplit is a useful function to get indexes using a factor.\n\ninds &lt;- with(murders, split(seq_along(region), region))\nmurders$state[inds$West]\n\n [1] \"Alaska\"     \"Arizona\"    \"California\" \"Colorado\"   \"Hawaii\"    \n [6] \"Idaho\"      \"Montana\"    \"Nevada\"     \"New Mexico\" \"Oregon\"    \n[11] \"Utah\"       \"Washington\" \"Wyoming\""
  },
  {
    "objectID": "05-vectorization.html#functions-for-subsetting",
    "href": "05-vectorization.html#functions-for-subsetting",
    "title": "5  Vectorization",
    "section": "5.5 Functions for subsetting",
    "text": "5.5 Functions for subsetting\nThe functions which, match and the operator %in% are useful for sub-setting\nHere are some examples:\n\nind &lt;- which(murders$state == \"California\")\nind\n\n[1] 5\n\nmurders[ind,]\n\n       state abb region population total     rate\n5 California  CA   West   37253956  1257 3.374138\n\n\n\nind &lt;- match(c(\"New York\", \"Florida\", \"Texas\"), murders$state)\nind\n\n[1] 33 10 44\n\n\n\nc(\"Boston\", \"Dakota\", \"Washington\") %in% murders$state\n\n[1] FALSE FALSE  TRUE"
  },
  {
    "objectID": "05-vectorization.html#sapply",
    "href": "05-vectorization.html#sapply",
    "title": "5  Vectorization",
    "section": "5.6 sapply",
    "text": "5.6 sapply\nYou can apply functions that don’t vectorize. Like this one:\n\ns &lt;- function(n){\n   return(sum(1:n))\n}\n\nTry it on a vector:\n\nns &lt;- c(25, 100, 1000)\ns(ns)\n\nWarning in 1:n: numerical expression has 3 elements: only the first used\n\n\n[1] 325\n\n\nWe can use sapply\n\nsapply(ns, s)\n\n[1]    325   5050 500500\n\n\nsapply will work on any vector, including lists."
  },
  {
    "objectID": "05-vectorization.html#exercises",
    "href": "05-vectorization.html#exercises",
    "title": "5  Vectorization",
    "section": "5.7 Exercises",
    "text": "5.7 Exercises\nNow we are ready to help your friend. Let’s give them options of places with low murders rates, mountains, and not too small.\nFor the following exercises do no load any packages other than dslabs.\n\nShow the subset of murders showing states with less than 1 per 100,000 deaths. Show all variables.\nShow the subset of murders showing states with less than 1 per 100,000 deaths and in the West of the US. Don’t show the region variable.\nShow the largest state with a rate less than 1 per 100,000.\nShow the state with a population of more than 10 million with the lowest rate.\nCompute the rate for each region of the US.\n\nMore practice exercises:\n\nCreate a vector of numbers that starts at 6, does not pass 55, and adds numbers in increments of 4/7: 6, 6 + 4/7, 6 + 8/7, and so on. How many numbers does the list have? Hint: use seq and length.\nMake this data frame:\n\n\ntemp &lt;- c(35, 88, 42, 84, 81, 30)\ncity &lt;- c(\"Beijing\", \"Lagos\", \"Paris\", \"Rio de Janeiro\", \n          \"San Juan\", \"Toronto\")\ncity_temps &lt;- data.frame(name = city, temperature = temp)\n\nConvert the temperatures to Celsius.\n\nCompute the following sum\n\n\\[\nS_n = 1+1/2^2 + 1/3^2 + \\dots 1/n^2\n\\]\nShow that as \\(n\\) gets bigger we get closer \\(\\pi^2/6\\).\n\nUse the %in% operator and the predefined object state.abb to create a logical vector that answers the question: which of the following are actual abbreviations: MA, ME, MI, MO, MU?\nExtend the code you used in the previous exercise to report the one entry that is not an actual abbreviation. Hint: use the ! operator, which turns FALSE into TRUE and viceversa, then which to obtain an index.\nShow all variables for New York, California, and Texas, in that order."
  },
  {
    "objectID": "06-tidyverse.html#tidy-data",
    "href": "06-tidyverse.html#tidy-data",
    "title": "6  Tidyverse",
    "section": "6.1 Tidy data",
    "text": "6.1 Tidy data\nThis is tidy:\n\n\n      country year fertility\n1     Germany 1960      2.41\n2 South Korea 1960      6.16\n3     Germany 1961      2.44\n4 South Korea 1961      5.99\n5     Germany 1962      2.47\n6 South Korea 1962      5.79\n\n\nOriginally, the data was in the following format:\n\n\n      country 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970\n1     Germany 2.41 2.44 2.47 2.49 2.49 2.48 2.44 2.37 2.28 2.17 2.04\n2 South Korea 6.16 5.99 5.79 5.57 5.36 5.16 4.99 4.85 4.73 4.62 4.53\n\n\nNot tidy.\nPart of what we learn in the data wrangling part of the class is to make data tidy."
  },
  {
    "objectID": "06-tidyverse.html#adding-a-column-with-mutate",
    "href": "06-tidyverse.html#adding-a-column-with-mutate",
    "title": "6  Tidyverse",
    "section": "6.2 Adding a column with mutate",
    "text": "6.2 Adding a column with mutate\n\nmurders &lt;- mutate(murders, rate = total/population*100000)\n\nNotice that here we used total and population inside the function, which are objects that are not defined in our workspace. But why don’t we get an error? This is non-standard evaluation where the context is used to know what variable names means."
  },
  {
    "objectID": "06-tidyverse.html#subsetting-with-filter",
    "href": "06-tidyverse.html#subsetting-with-filter",
    "title": "6  Tidyverse",
    "section": "6.3 Subsetting with filter",
    "text": "6.3 Subsetting with filter\n\nfilter(murders, rate &lt;= 0.71)\n\n          state abb        region population total      rate\n1        Hawaii  HI          West    1360301     7 0.5145920\n2          Iowa  IA North Central    3046355    21 0.6893484\n3 New Hampshire  NH     Northeast    1316470     5 0.3798036\n4  North Dakota  ND North Central     672591     4 0.5947151\n5       Vermont  VT     Northeast     625741     2 0.3196211"
  },
  {
    "objectID": "06-tidyverse.html#selecting-columns-with-select",
    "href": "06-tidyverse.html#selecting-columns-with-select",
    "title": "6  Tidyverse",
    "section": "6.4 Selecting columns with select",
    "text": "6.4 Selecting columns with select\n\nnew_table &lt;- select(murders, state, region, rate)\nfilter(new_table, rate &lt;= 0.71)\n\n          state        region      rate\n1        Hawaii          West 0.5145920\n2          Iowa North Central 0.6893484\n3 New Hampshire     Northeast 0.3798036\n4  North Dakota North Central 0.5947151\n5       Vermont     Northeast 0.3196211"
  },
  {
    "objectID": "06-tidyverse.html#the-pipe-or",
    "href": "06-tidyverse.html#the-pipe-or",
    "title": "6  Tidyverse",
    "section": "6.5 The pipe: |> or %>%",
    "text": "6.5 The pipe: |&gt; or %&gt;%\nWe use the pipe to chain a series of operations… for example if we want to select columns and then filter rows we chain like this:\n\\[ \\mbox{original data }\n\\rightarrow \\mbox{ select }\n\\rightarrow \\mbox{ filter } \\]\nThe code looks like this:\n\nmurders |&gt; select(state, region, rate) |&gt; filter(rate &lt;= 0.71)\n\n          state        region      rate\n1        Hawaii          West 0.5145920\n2          Iowa North Central 0.6893484\n3 New Hampshire     Northeast 0.3798036\n4  North Dakota North Central 0.5947151\n5       Vermont     Northeast 0.3196211\n\n\nThe object on the left of the pipe is used as the first argument for the function on the right.\nThe second argument becomes the first, the third the second, and so on…\n\n16 |&gt; sqrt() |&gt; log(base = 2)\n\n[1] 2"
  },
  {
    "objectID": "06-tidyverse.html#summarizing-data",
    "href": "06-tidyverse.html#summarizing-data",
    "title": "6  Tidyverse",
    "section": "6.6 Summarizing data",
    "text": "6.6 Summarizing data\nHere is how it works:\n\nmurders |&gt; summarize(avg = mean(rate))\n\n       avg\n1 2.779125\n\n\nLet’s compute murder rate for the US. Is the above it?\nNo the rate is NOT the average of rates.\n\nmurders |&gt; summarize(rate = sum(total)/sum(population)*100000)\n\n      rate\n1 3.034555\n\n\n\n6.6.1 Multiple summaries\nWe want the median, minimum and max population size:\n\nmurders |&gt; summarize(median = median(population), min = min(population), max = max(population))\n\n   median    min      max\n1 4339367 563626 37253956\n\n\nWhy don’t we use quantiles?\n\nmurders |&gt; summarize(quantiles = quantile(population, c(0.5, 0, 1)))\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n  quantiles\n1   4339367\n2    563626\n3  37253956\n\n\nFor multiple summaries we use reframe\n\nmurders |&gt; reframe(quantiles = quantile(population, c(0.5, 0, 1)))\n\n  quantiles\n1   4339367\n2    563626\n3  37253956\n\n\nHowever, if we want a column per summary, as the summarize call above, we have to define a function that returns a data frame like this:\n\nmedian_min_max &lt;- function(x){\n  qs &lt;- quantile(x, c(0.5, 0, 1))\n  data.frame(median = qs[1], min = qs[2], max = qs[3])\n}\n\nThen we can call summarize as above:\n\nmurders |&gt; summarize(median_min_max(population))\n\n   median    min      max\n1 4339367 563626 37253956\n\n\n\n\n6.6.2 Group then summarize with group_by\nLet’s compute murder rate by region.\nTake a close look at this output? How is it different than the original?\n\nmurders |&gt; group_by(region)\n\n# A tibble: 51 × 6\n# Groups:   region [4]\n   state                abb   region    population total  rate\n   &lt;chr&gt;                &lt;chr&gt; &lt;fct&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Alabama              AL    South        4779736   135  2.82\n 2 Alaska               AK    West          710231    19  2.68\n 3 Arizona              AZ    West         6392017   232  3.63\n 4 Arkansas             AR    South        2915918    93  3.19\n 5 California           CA    West        37253956  1257  3.37\n 6 Colorado             CO    West         5029196    65  1.29\n 7 Connecticut          CT    Northeast    3574097    97  2.71\n 8 Delaware             DE    South         897934    38  4.23\n 9 District of Columbia DC    South         601723    99 16.5 \n10 Florida              FL    South       19687653   669  3.40\n# ℹ 41 more rows\n\n\nNote the Groups: region [4] when we print the object. Although not immediately obvious from its appearance, this is now a special data frame called a grouped data frame, and dplyr functions, in particular summarize, will behave differently when acting on this object.\n\nmurders |&gt; group_by(region) |&gt; summarize(rate = sum(total) / sum(population) * 100000)\n\n# A tibble: 4 × 2\n  region         rate\n  &lt;fct&gt;         &lt;dbl&gt;\n1 Northeast      2.66\n2 South          3.63\n3 North Central  2.73\n4 West           2.66\n\n\nThe summarize function applies the summarization to each group separately.\nFor another example, let’s compute the median, minimum, and maximum population in the four regions of the country using the median_min_max defined above:\n\nmurders |&gt; group_by(region) |&gt; summarize(median_min_max(population))\n\n# A tibble: 4 × 4\n  region          median    min      max\n  &lt;fct&gt;            &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n1 Northeast     3574097  625741 19378102\n2 South         4625364  601723 25145561\n3 North Central 5495456. 672591 12830632\n4 West          2700551  563626 37253956"
  },
  {
    "objectID": "06-tidyverse.html#ungroup",
    "href": "06-tidyverse.html#ungroup",
    "title": "6  Tidyverse",
    "section": "6.7 ungroup",
    "text": "6.7 ungroup\nYou can also summarize a variable but not collapse the dataset. We use mutate instead of summarize. Here is an example where we add a column with the population in each region and the number of states in the region, shown for each state. When we do this, we usually want to ungroup before continuing our analysis.\n\nmurders |&gt; group_by(region) |&gt; \n  mutate(region_pop = sum(population), n = n()) |&gt;\n  ungroup()\n\n# A tibble: 51 × 8\n   state                abb   region    population total  rate region_pop     n\n   &lt;chr&gt;                &lt;chr&gt; &lt;fct&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt;\n 1 Alabama              AL    South        4779736   135  2.82  115674434    17\n 2 Alaska               AK    West          710231    19  2.68   71945553    13\n 3 Arizona              AZ    West         6392017   232  3.63   71945553    13\n 4 Arkansas             AR    South        2915918    93  3.19  115674434    17\n 5 California           CA    West        37253956  1257  3.37   71945553    13\n 6 Colorado             CO    West         5029196    65  1.29   71945553    13\n 7 Connecticut          CT    Northeast    3574097    97  2.71   55317240     9\n 8 Delaware             DE    South         897934    38  4.23  115674434    17\n 9 District of Columbia DC    South         601723    99 16.5   115674434    17\n10 Florida              FL    South       19687653   669  3.40  115674434    17\n# ℹ 41 more rows\n\n\n\n6.7.1 pull\nTidyverse function always returns a data frame. Even if its just one number.\n\nmurders |&gt; \n  summarize(rate = sum(total)/sum(population)*100000) |&gt;\n  class()\n\n[1] \"data.frame\"\n\n\nTo get a number use pull\n\nmurders |&gt; \n  summarize(rate = sum(total)/sum(population)*100000) |&gt;\n  pull(rate) \n\n[1] 3.034555"
  },
  {
    "objectID": "06-tidyverse.html#sorting-data-frames",
    "href": "06-tidyverse.html#sorting-data-frames",
    "title": "6  Tidyverse",
    "section": "6.8 Sorting data frames",
    "text": "6.8 Sorting data frames\nStates order by rate\n\nmurders |&gt; arrange(rate) |&gt; head()\n\n          state abb        region population total      rate\n1       Vermont  VT     Northeast     625741     2 0.3196211\n2 New Hampshire  NH     Northeast    1316470     5 0.3798036\n3        Hawaii  HI          West    1360301     7 0.5145920\n4  North Dakota  ND North Central     672591     4 0.5947151\n5          Iowa  IA North Central    3046355    21 0.6893484\n6         Idaho  ID          West    1567582    12 0.7655102\n\n\nIf we want decreasing we can either use the negative or, for more readability, use desc:\n\nmurders |&gt; arrange(desc(rate)) |&gt; head()\n\n                 state abb        region population total      rate\n1 District of Columbia  DC         South     601723    99 16.452753\n2            Louisiana  LA         South    4533372   351  7.742581\n3             Missouri  MO North Central    5988927   321  5.359892\n4             Maryland  MD         South    5773552   293  5.074866\n5       South Carolina  SC         South    4625364   207  4.475323\n6             Delaware  DE         South     897934    38  4.231937\n\n\nWe can use two variables as well:\n\nmurders |&gt; arrange(region, desc(rate)) |&gt; head(11)\n\n                  state abb    region population total       rate\n1          Pennsylvania  PA Northeast   12702379   457  3.5977513\n2            New Jersey  NJ Northeast    8791894   246  2.7980319\n3           Connecticut  CT Northeast    3574097    97  2.7139722\n4              New York  NY Northeast   19378102   517  2.6679599\n5         Massachusetts  MA Northeast    6547629   118  1.8021791\n6          Rhode Island  RI Northeast    1052567    16  1.5200933\n7                 Maine  ME Northeast    1328361    11  0.8280881\n8         New Hampshire  NH Northeast    1316470     5  0.3798036\n9               Vermont  VT Northeast     625741     2  0.3196211\n10 District of Columbia  DC     South     601723    99 16.4527532\n11            Louisiana  LA     South    4533372   351  7.7425810"
  },
  {
    "objectID": "06-tidyverse.html#exercises",
    "href": "06-tidyverse.html#exercises",
    "title": "6  Tidyverse",
    "section": "6.9 Exercises",
    "text": "6.9 Exercises\nLet’s redo the exercises from previous chapter but now with tidyverse:\n\nShow the subset of murders showing states with less than 1 per 100,000 deaths. Show all variables.\nShow the subset of murders showing states with less than 1 per 100,000 deaths and in the West of the US. Don’t show the region variable.\nShow the largest state with a rate less than 1 per 100,000.\nShow the state with a population of more than 10 million with the lowest rate.\nCompute the rate for each region of the US.\n\nFor the next exercises we will be using the data from the survey collected by the United States National Center for Health Statistics (NCHS). This center has conducted a series of health and nutrition surveys since the 1960’s. Starting in 1999, about 5,000 individuals of all ages have been interviewed every year and they complete the health examination component of the survey. Part of the data is made available via the NHANES package. Once you install the NHANES package, you can load the data like this:\n\nlibrary(NHANES)\n\n\nCheck for consistency between Race1 and Race3. Do any rows have different entries?\nDefine a new race variable that has as few NA and Other as possible.\nCompute proportion of individuals that smoked at the time of the survey, by race category and gender. Keep track of how many people answered the question. Order the result by the number that answered. Read the help file for NHANES carefully before doing this one.\nCreate a new dataset that combines the Mexican and Hispanic, and removes the Other category. Hint: use the function forcats::fct_collapse().\nRecompute proportion of individuals that smoke now by race category and gender. Order by rate of smokers.\nCompute the median age by race category and gender order by Age.\nNow redo the smoking rate calculation by age group. But first, remove individuals with no group and remove any age groups for which less than 10 people answered the question. Within each age group and Gender order by percent that smokes."
  },
  {
    "objectID": "07-dates-and-times.html#the-date-data-type",
    "href": "07-dates-and-times.html#the-date-data-type",
    "title": "7  Dates and times",
    "section": "7.1 The date data type",
    "text": "7.1 The date data type\nWe have described three main types of vectors: numeric, character, and logical. When analyzing data, we often encounter variables that are dates. Although we can represent a date with a string, for example September 10, 2023`, once we pick a reference day, referred to as the epoch by computer programmers, they can be converted to numbers by calculating the number of days since the epoch. In R and Unix, the epoch is defined as January 1, 1970. So, for example, January 2, 1970 is day 1, December 31, 1969 is day -1, and so on.\n\nx &lt;- as.Date(\"1970-01-01\")\ntypeof(x)\n\n[1] \"double\"\n\nclass(x)\n\n[1] \"Date\"\n\nas.numeric(x)\n\n[1] 0\n\n\n\nx &lt;- Sys.Date()\nas.numeric(x)\n\n[1] 19610\n\n\nThe date class let’s R know that it is data so you can extract year, months, days of the week etc…\nYou can make them look good using the format function:\n\nformat(x, \"%B %d, %Y\")\n\n[1] \"September 10, 2023\"\n\n\nThere are many formats:\n\nformat(x, \"%b %d %y\")\n\n[1] \"Sep 10 23\"\n\n\nTo see all the possibilities you can consult the data and time formats cheat sheet"
  },
  {
    "objectID": "07-dates-and-times.html#predefined-objects",
    "href": "07-dates-and-times.html#predefined-objects",
    "title": "7  Dates and times",
    "section": "7.2 Predefined objects",
    "text": "7.2 Predefined objects\n\nmonth.name\n\n [1] \"January\"   \"February\"  \"March\"     \"April\"     \"May\"       \"June\"     \n [7] \"July\"      \"August\"    \"September\" \"October\"   \"November\"  \"December\" \n\nmonth.abb\n\n [1] \"Jan\" \"Feb\" \"Mar\" \"Apr\" \"May\" \"Jun\" \"Jul\" \"Aug\" \"Sep\" \"Oct\" \"Nov\" \"Dec\""
  },
  {
    "objectID": "07-dates-and-times.html#sec-lubridate",
    "href": "07-dates-and-times.html#sec-lubridate",
    "title": "7  Dates and times",
    "section": "7.3 The lubridate package",
    "text": "7.3 The lubridate package\nThe lubridate package provides tools to work with date and times.\n\nlibrary(lubridate)\n\nAn example of the many useful functions is as_date\n\nas_date(0)\n\n[1] \"1970-01-01\"\n\n\nAnother one is\n\ntoday()\n\n[1] \"2023-09-10\"\n\n\nWe can generate random dates like this:\n\nset.seed(2013 - 9 - 10)\nn &lt;- 10 \ndates &lt;- as_date(sample(0:as.numeric(today()), n, replace = TRUE))\n\nThe functions year, month and day extract those values:\n\ndata.frame(date = dates, month = month(dates), day = day(dates), year = year(dates))\n\n         date month day year\n1  1987-10-06    10   6 1987\n2  2020-10-02    10   2 2020\n3  1990-05-23     5  23 1990\n4  2009-03-04     3   4 2009\n5  1977-01-30     1  30 1977\n6  1986-03-06     3   6 1986\n7  2022-02-02     2   2 2022\n8  1977-07-29     7  29 1977\n9  2022-10-11    10  11 2022\n10 2007-11-08    11   8 2007\n\n\nWe can also extract the month labels:\n\nmonth(dates, label = TRUE)\n\n [1] Oct Oct May Mar Jan Mar Feb Jul Oct Nov\n12 Levels: Jan &lt; Feb &lt; Mar &lt; Apr &lt; May &lt; Jun &lt; Jul &lt; Aug &lt; Sep &lt; ... &lt; Dec\n\n\nAnother useful set of functions are the parsers that convert strings into dates. The function ymd assumes the dates are in the format YYYY-MM-DD and tries to parse as well as possible.\n\nx &lt;- c(20090101, \"2009-01-02\", \"2009 01 03\", \"2009-1-4\",\n       \"2009-1, 5\", \"Created on 2009 1 6\", \"200901 !!! 07\")\nymd(x)\n\n[1] \"2009-01-01\" \"2009-01-02\" \"2009-01-03\" \"2009-01-04\" \"2009-01-05\"\n[6] \"2009-01-06\" \"2009-01-07\"\n\n\nA further complication comes from the fact that dates often come in different formats in which the order of year, month, and day are different. The preferred format is to show year (with all four digits), month (two digits), and then day, or what is called the ISO 8601. Specifically we use YYYY-MM-DD so that if we order the string, it will be ordered by date. You can see the function ymd returns them in this format.\nBut, what if you encounter dates such as “09/01/02”? This could be September 1, 2002 or January 2, 2009 or January 9, 2002. lubridate provides options:\n\nx &lt;- \"09/01/02\"\nymd(x)\n\n[1] \"2009-01-02\"\n\nmdy(x)\n\n[1] \"2002-09-01\"\n\ndmy(x)\n\n[1] \"2002-01-09\"\n\n\nThe lubridate package is also useful for dealing with times:\n\nnow()\n\n[1] \"2023-09-10 16:21:24 EDT\"\n\n\nYou can provide time zones too:\n\nnow(\"GMT\")\n\n[1] \"2023-09-10 20:21:24 GMT\"\n\n\nYou can see all the available time zones with OlsonNames() function.\nWe can extract hours, minutes, and seconds:\n\nnow() |&gt; hour()\n\n[1] 16\n\nnow() |&gt; minute()\n\n[1] 21\n\nnow() |&gt; second()\n\n[1] 24.42772\n\n\nThe package also includes a function to parse strings into times as well as parsers for time objects that include dates:\n\nx &lt;- c(\"12:34:56\")\nhms(x)\n\n[1] \"12H 34M 56S\"\n\nx &lt;- \"Nov/2/2012 12:34:56\"\nmdy_hms(x)\n\n[1] \"2012-11-02 12:34:56 UTC\""
  },
  {
    "objectID": "07-dates-and-times.html#sequences",
    "href": "07-dates-and-times.html#sequences",
    "title": "7  Dates and times",
    "section": "7.4 Sequences",
    "text": "7.4 Sequences\n\nx &lt;- seq(today(), today() + 7, by = \"days\")"
  },
  {
    "objectID": "07-dates-and-times.html#rounding",
    "href": "07-dates-and-times.html#rounding",
    "title": "7  Dates and times",
    "section": "7.5 Rounding",
    "text": "7.5 Rounding\n\nx &lt;- seq(today() - 365 + 1, today(), by = \"days\")\ntable(floor_date(x, unit = \"week\"))\n\n\n2022-09-11 2022-09-18 2022-09-25 2022-10-02 2022-10-09 2022-10-16 2022-10-23 \n         7          7          7          7          7          7          7 \n2022-10-30 2022-11-06 2022-11-13 2022-11-20 2022-11-27 2022-12-04 2022-12-11 \n         7          7          7          7          7          7          7 \n2022-12-18 2022-12-25 2023-01-01 2023-01-08 2023-01-15 2023-01-22 2023-01-29 \n         7          7          7          7          7          7          7 \n2023-02-05 2023-02-12 2023-02-19 2023-02-26 2023-03-05 2023-03-12 2023-03-19 \n         7          7          7          7          7          7          7 \n2023-03-26 2023-04-02 2023-04-09 2023-04-16 2023-04-23 2023-04-30 2023-05-07 \n         7          7          7          7          7          7          7 \n2023-05-14 2023-05-21 2023-05-28 2023-06-04 2023-06-11 2023-06-18 2023-06-25 \n         7          7          7          7          7          7          7 \n2023-07-02 2023-07-09 2023-07-16 2023-07-23 2023-07-30 2023-08-06 2023-08-13 \n         7          7          7          7          7          7          7 \n2023-08-20 2023-08-27 2023-09-03 2023-09-10 \n         7          7          7          1 \n\ntable(floor_date(x, unit = \"year\"))\n\n\n2022-01-01 2023-01-01 \n       112        253 \n\n\nWhat if I want to start counting on Mondays?\n\nx &lt;- seq(today() - weeks(1) + 1, today(), by = \"days\")\nwday(x)\n\n[1] 2 3 4 5 6 7 1\n\ndata.frame(day = x, week = floor_date(x, unit = \"week\", week_start = \"Sun\"))\n\n         day       week\n1 2023-09-04 2023-09-03\n2 2023-09-05 2023-09-03\n3 2023-09-06 2023-09-03\n4 2023-09-07 2023-09-03\n5 2023-09-08 2023-09-03\n6 2023-09-09 2023-09-03\n7 2023-09-10 2023-09-10"
  },
  {
    "objectID": "07-dates-and-times.html#day-of-the-year-or-month",
    "href": "07-dates-and-times.html#day-of-the-year-or-month",
    "title": "7  Dates and times",
    "section": "7.6 day of the year or month",
    "text": "7.6 day of the year or month\n\nyday(x)\n\n[1] 247 248 249 250 251 252 253\n\nmday(x)\n\n[1]  4  5  6  7  8  9 10"
  },
  {
    "objectID": "07-dates-and-times.html#exercises",
    "href": "07-dates-and-times.html#exercises",
    "title": "7  Dates and times",
    "section": "7.7 Exercises",
    "text": "7.7 Exercises\nIn the previous exercise section, we wrangled data from a PDF file containing vital statistics from Puerto Rico. We did this for the month of September. Below we include code that does it for all 12 months.\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(purrr)\nlibrary(pdftools)\nlibrary(dslabs)\n\nfn &lt;- system.file(\"extdata\", \"RD-Mortality-Report_2015-18-180531.pdf\",\n                  package=\"dslabs\")\ndat &lt;- map_df(str_split(pdf_text(fn), \"\\n\"), function(s){\n  s &lt;- str_trim(s)\n  header_index &lt;- str_which(s, \"2015\")[1]\n  tmp &lt;- str_split(s[header_index], \"\\\\s+\", simplify = TRUE)\n  month &lt;- tmp[1]\n  header &lt;- tmp[-1]\n  tail_index  &lt;- str_which(s, \"Total\")\n  n &lt;- str_count(s, \"\\\\d+\")\n  out &lt;- c(1:header_index, which(n == 1), \n           which(n &gt;= 28), tail_index:length(s))\n  res &lt;- s[-out] |&gt;  str_remove_all(\"[^\\\\d\\\\s]\") |&gt; str_trim() |&gt;\n    str_split_fixed(\"\\\\s+\", n = 6) \n  res &lt;- data.frame(res[,1:5]) |&gt; as_tibble() |&gt; \n    setNames(c(\"day\", header)) |&gt;\n    mutate(month = month, day = as.numeric(day)) |&gt;\n    pivot_longer(-c(day, month), names_to = \"year\", values_to = \"deaths\") |&gt;\n    mutate(deaths = as.numeric(deaths)) |&gt;\n    mutate(month = str_to_title(month)) |&gt;\n    mutate(month = if_else(month==\"Ago\", \"Aug\", month))\n}) \n\n1. We want to make a plot of death counts versus date. A first step is to convert the month variable from characters to numbers. Hint: use months.abb.\n2. Create a new column date with the date for each observation. Hint: use the make_date function.\n3. Plot deaths versus date. Hint: the plot function can take dates for either axis.\n4. Note that after May 31, 2018, the deaths are all 0. The data is probably not entered yet. We also see a drop off starting around May 1. Redefine dat to exclude observations taken on or after May 1, 2018. Then, remake the plot.\n5. Repeat the plot but use the day of the year on the x-axis instead of date and different colors for the different year. Hint: Use the col argument in plot.\n6. Compute the number deaths per day by month.\n7. Show the deaths per day for July and for September. What do you notice?\n8. Compute deaths per week and make a plot."
  }
]